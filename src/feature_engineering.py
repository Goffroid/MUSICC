import numpy as np
import os
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.decomposition import PCA, TruncatedSVD
from sklearn.cluster import KMeans, MiniBatchKMeans
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class FeatureEngineer:
    def __init__(self, project_root='.', fast_mode=True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–∂–µ–Ω–µ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Args:
            project_root: –∫–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
            fast_mode: —Ä–µ–∂–∏–º –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        self.project_root = project_root
        self.fast_mode = fast_mode
        
        if fast_mode:
            self.scaler = StandardScaler()
        else:
            self.scaler = RobustScaler()  
        
        self.pca = PCA(n_components=0.95, random_state=42)
        self.feature_selector = None
    
    def ensure_directory_exists(self, path):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ"""
        os.makedirs(os.path.dirname(path), exist_ok=True)
    
    def normalize_features(self, X, scaler_type='standard'):
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤—ã–±–æ—Ä–æ–º –º–µ—Ç–æ–¥–∞
        
        Args:
            X: –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            scaler_type: —Ç–∏–ø –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ ('standard', 'minmax', 'robust')
        """
        print("üîß –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        if len(X) == 0:
            return X
            
        original_shape = X.shape
        X_flat = X.reshape(-1, X.shape[-1])
        
        with tqdm(total=2, desc="–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è", unit="—ç—Ç–∞–ø",
                 bar_format="{l_bar}{bar:20}{r_bar}{bar:-20b}") as pbar:
            
            if scaler_type == 'standard':
                scaler = StandardScaler()
            elif scaler_type == 'minmax':
                scaler = MinMaxScaler()
            elif scaler_type == 'robust':
                scaler = RobustScaler()
            else:
                scaler = StandardScaler()
            
            X_normalized = scaler.fit_transform(X_flat)
            pbar.update(2)
        
        return X_normalized.reshape(original_shape)
    
    def extract_temporal_features(self, X, feature_types=['basic']):
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        
        Args:
            X: –≤—Ö–æ–¥–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            feature_types: —Ç–∏–ø—ã –∏–∑–≤–ª–µ–∫–∞–µ–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ 
                         ['basic', 'statistical', 'temporal', 'all']
        """
        print("üîß –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        temporal_features = []
        n_samples = len(X)
        
        with tqdm(total=n_samples, desc="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", unit="–ø–æ—Å–ª–µ–¥.",
                 bar_format="{l_bar}{bar:30}{r_bar}{bar:-30b}") as pbar:
            
            for seq in X:
                features = []
                
                if 'basic' in feature_types or 'all' in feature_types:
                    mean_features = np.mean(seq, axis=0)
                    features.extend(mean_features)
                    
                    std_features = np.std(seq, axis=0)
                    features.extend(std_features)
                
                if 'statistical' in feature_types or 'all' in feature_types:
                    min_features = np.min(seq, axis=0)
                    max_features = np.max(seq, axis=0)
                    features.extend(min_features)
                    features.extend(max_features)
                    
                    q25 = np.percentile(seq, 25, axis=0)
                    q50 = np.percentile(seq, 50, axis=0)
                    q75 = np.percentile(seq, 75, axis=0)
                    features.extend(q25)
                    features.extend(q50)
                    features.extend(q75)
                
                if 'temporal' in feature_types or 'all' in feature_types:
                    if len(seq) > 1:
                        diff_mean = np.diff(seq, axis=0).mean(axis=0)
                        features.extend(diff_mean)
                        
                        if len(seq) > 2:
                            autocorr = []
                            for i in range(seq.shape[1]):
                                corr = np.corrcoef(seq[:-1, i], seq[1:, i])[0, 1]
                                autocorr.append(corr if not np.isnan(corr) else 0)
                            features.extend(autocorr)
                
                if 'all' in feature_types:
                    energy = np.sum(seq ** 2, axis=0) / len(seq)
                    features.extend(energy)
                
                temporal_features.append(features)
                pbar.update(1)
        
        feature_lengths = [len(f) for f in temporal_features]
        if len(set(feature_lengths)) > 1:
            print(f"‚ö†Ô∏è  –†–∞–∑–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {set(feature_lengths)}")
            min_len = min(feature_lengths)
            temporal_features = [f[:min_len] for f in temporal_features]
        
        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –ø—Ä–∏–º–µ—Ä: {len(temporal_features[0])}")
        return np.array(temporal_features)
    
    def reduce_dimensionality(self, X, method='pca', n_components=0.95):
        """
        –£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Args:
            X: –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            method: –º–µ—Ç–æ–¥ ('pca', 'svd', 'tsne')
            n_components: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏–ª–∏ –¥–æ–ª—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏
        """
        print(f"üîß –£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ ({method})...")
        
        if self.fast_mode and X.shape[1] > 50:
            print(f"‚ö° –ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º: –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º {X.shape[1]} -> 50 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            return X[:, :50]
        
        with tqdm(total=2, desc="–£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏", unit="—ç—Ç–∞–ø",
                 bar_format="{l_bar}{bar:20}{r_bar}{bar:-20b}") as pbar:
            
            if method == 'pca':
                if isinstance(n_components, float):
                    self.pca = PCA(n_components=n_components, random_state=42)
                else:
                    self.pca = PCA(n_components=min(n_components, X.shape[1]), random_state=42)
                
                X_reduced = self.pca.fit_transform(X)
                pbar.update(1)
                
                explained_var = self.pca.explained_variance_ratio_.sum()
                print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {X_reduced.shape[1]} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç "
                      f"({explained_var*100:.1f}% –¥–∏—Å–ø–µ—Ä—Å–∏–∏)")
                
            elif method == 'svd':
                n_comp = min(n_components if isinstance(n_components, int) else 50, X.shape[1])
                svd = TruncatedSVD(n_components=n_comp, random_state=42)
                X_reduced = svd.fit_transform(X)
                pbar.update(1)
                
                print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {X_reduced.shape[1]} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (SVD)")
                
            elif method == 'tsne':
                print("‚ö†Ô∏è  t-SNE –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–º –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
                tsne = TSNE(n_components=2 if isinstance(n_components, int) else 2, 
                          random_state=42, 
                          perplexity=min(30, X.shape[0] // 3))
                X_reduced = tsne.fit_transform(X)
                pbar.update(1)
                
                print(f"   –£–º–µ–Ω—å—à–µ–Ω–æ –¥–æ 2D (t-SNE)")
            else:
                print("‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
                X_reduced = X
            
            pbar.update(1)
        
        return X_reduced
    
    def select_features(self, X, y, method='kbest', k=10):
        """
        –û—Ç–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Args:
            X: –ø—Ä–∏–∑–Ω–∞–∫–∏
            y: —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            method: –º–µ—Ç–æ–¥ –æ—Ç–±–æ—Ä–∞ ('kbest', 'mutual_info')
            k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–±–æ—Ä–∞
        """
        print(f"üîç –û—Ç–±–æ—Ä {k} –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ({method})...")
        
        if X.shape[1] <= k:
            print(f"   –£–∂–µ –º–µ–Ω—å—à–µ {k} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–±–æ—Ä")
            return X
        
        with tqdm(total=2, desc="–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", unit="—ç—Ç–∞–ø",
                 bar_format="{l_bar}{bar:20}{r_bar}{bar:-20b}") as pbar:
            
            if method == 'kbest':
                self.feature_selector = SelectKBest(f_classif, k=min(k, X.shape[1]))
            elif method == 'mutual_info':
                self.feature_selector = SelectKBest(mutual_info_classif, k=min(k, X.shape[1]))
            else:
                print(f"‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –æ—Ç–±–æ—Ä–∞: {method}")
                return X
            
            X_selected = self.feature_selector.fit_transform(X, y)
            pbar.update(1)
            
            selected_indices = self.feature_selector.get_support(indices=True)
            scores = self.feature_selector.scores_
            
            print(f"   –í—ã–±—Ä–∞–Ω–æ {len(selected_indices)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ {X.shape[1]}")
            print(f"   –õ—É—á—à–∏–π –ø—Ä–∏–∑–Ω–∞–∫: –∏–Ω–¥–µ–∫—Å {selected_indices[0]}, score={scores[selected_indices[0]]:.3f}")
            
            pbar.update(1)
        
        return X_selected
    
    def cluster_data(self, X, n_clusters=8, method='kmeans'):
        """
        –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            X: –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            n_clusters: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
            method: –º–µ—Ç–æ–¥ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ ('kmeans', 'minibatch')
        """
        print(f"üîß –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ {n_clusters} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ ({method})...")
        
        with tqdm(total=2, desc="–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è", unit="—ç—Ç–∞–ø",
                 bar_format="{l_bar}{bar:20}{r_bar}{bar:-20b}") as pbar:
            
            if method == 'kmeans':
                if self.fast_mode:
                    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=3, verbose=0)
                else:
                    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10, verbose=0)
            elif method == 'minibatch':
                kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, verbose=0)
            else:
                print(f"‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {method}")
                return None
            
            labels = kmeans.fit_predict(X)
            pbar.update(1)
            
            inertia = kmeans.inertia_
            print(f"   –ò–Ω–µ—Ä—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {inertia:.2f}")
            
            pbar.update(1)
        
        return labels
    
    def create_visualizations(self, X, y, save_plots=True):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            X: –ø—Ä–∏–∑–Ω–∞–∫–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å 3D –∏–ª–∏ 2D)
            y: —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            save_plots: —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ –≥—Ä–∞—Ñ–∏–∫–∏
        """
        print("üìä –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
        
        if save_plots:
            plot_dir = os.path.join(self.project_root, 'results', 'plots')
            self.ensure_directory_exists(plot_dir)
        
        n_plots = 4 if self.fast_mode else 6
        with tqdm(total=n_plots, desc="–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤", unit="–≥—Ä–∞—Ñ–∏–∫",
                 bar_format="{l_bar}{bar:20}{r_bar}{bar:-20b}") as pbar:
            
            fig = plt.figure(figsize=(15, 10))
            
            ax1 = plt.subplot(2, 3, 1)
            plt.hist(y, bins=min(50, len(np.unique(y))), alpha=0.7, 
                    color='skyblue', edgecolor='black')
            plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–æ—Ç', fontsize=12, fontweight='bold')
            plt.xlabel('–í—ã—Å–æ—Ç–∞ –Ω–æ—Ç—ã')
            plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
            plt.grid(alpha=0.3)
            pbar.update(1)
            
            ax2 = plt.subplot(2, 3, 2)
            
            if len(X.shape) == 3:
                X_2d = X.reshape(-1, X.shape[-1])
            else:
                X_2d = X
            
            if X_2d.shape[1] <= 20 and X_2d.shape[0] > 1: 
                try:
                    corr_matrix = np.corrcoef(X_2d.T)
                    sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', 
                               square=True, cbar_kws={"shrink": 0.8})
                    plt.title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=12, fontweight='bold')
                except Exception as e:
                    plt.text(0.5, 0.5, f'–û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\n{str(e)[:30]}', 
                            ha='center', va='center')
            else:
                plt.text(0.5, 0.5, f'–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n({X_2d.shape[1]} > 20)', 
                        ha='center', va='center')
            pbar.update(1)
            
            ax3 = plt.subplot(2, 3, 3)
            
            if len(X.shape) == 3:
                if X.shape[2] > 0:
                    first_feature_values = X[:, :, 0].flatten()
                else:
                    first_feature_values = np.array([])
            else:
                if X.shape[1] > 0:
                    first_feature_values = X[:, 0]
                else:
                    first_feature_values = np.array([])
            
            if len(first_feature_values) > 0:
                plt.hist(first_feature_values, bins=30, alpha=0.7, 
                        color='lightcoral', edgecolor='black')
                plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ 1-–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞', fontsize=12, fontweight='bold')
                plt.xlabel('–ó–Ω–∞—á–µ–Ω–∏–µ')
                plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
                plt.grid(alpha=0.3)
            else:
                plt.text(0.5, 0.5, '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö', ha='center', va='center')
            pbar.update(1)
            
            ax4 = plt.subplot(2, 3, 4)
            if len(y) > 0:
                unique_notes, counts = np.unique(y, return_counts=True)
                top_n = min(20, len(unique_notes))
                top_indices = np.argsort(counts)[-top_n:][::-1]
                top_notes = unique_notes[top_indices]
                top_counts = counts[top_indices]
                
                bars = plt.bar(range(len(top_notes)), top_counts, 
                              color='gold', edgecolor='black')
                plt.title(f'–¢–æ–ø-{top_n} —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö –Ω–æ—Ç', fontsize=12, fontweight='bold')
                plt.xlabel('–ù–æ—Ç–∞')
                plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
                plt.xticks(range(len(top_notes)), [f"{int(n)}" for n in top_notes], 
                          rotation=45, fontsize=8)
                plt.grid(alpha=0.3, axis='y')
                
                for i, (bar, count) in enumerate(zip(bars[:10], top_counts[:10])):
                    height = bar.get_height()
                    plt.text(bar.get_x() + bar.get_width()/2., height,
                            f'{int(count)}', ha='center', va='bottom', fontsize=8)
            else:
                plt.text(0.5, 0.5, '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö', ha='center', va='center')
            pbar.update(1)
            
            if not self.fast_mode:
                ax5 = plt.subplot(2, 3, 5)
                
                if len(X.shape) == 3:
                    X_mean = X.mean(axis=1)
                    n_features_to_plot = min(5, X_mean.shape[1])
                    data_to_plot = [X_mean[:, i] for i in range(n_features_to_plot)]
                else:
                    n_features_to_plot = min(5, X.shape[1])
                    data_to_plot = [X[:, i] for i in range(n_features_to_plot)]
                
                if len(data_to_plot) > 0:
                    box = plt.boxplot(data_to_plot, patch_artist=True)
                    colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow', 'lightgray']
                    for patch, color in zip(box['boxes'], colors[:len(data_to_plot)]):
                        patch.set_facecolor(color)
                    
                    plt.title(f'Box plot –ø–µ—Ä–≤—ã—Ö {len(data_to_plot)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', 
                             fontsize=12, fontweight='bold')
                    plt.xlabel('–ü—Ä–∏–∑–Ω–∞–∫')
                    plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')
                    plt.xticks(range(1, len(data_to_plot) + 1), 
                              [f'–ü—Ä–∏–∑–Ω.{i}' for i in range(len(data_to_plot))])
                    plt.grid(alpha=0.3, axis='y')
                else:
                    plt.text(0.5, 0.5, '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö', ha='center', va='center')
                pbar.update(1)
                
                ax6 = plt.subplot(2, 3, 6)
                ax6.axis('off')
                
                if len(X.shape) == 3:
                    shape_info = f"3D: {X.shape[0]}√ó{X.shape[1]}√ó{X.shape[2]}"
                    n_features = X.shape[2]
                else:
                    shape_info = f"2D: {X.shape[0]}√ó{X.shape[1]}"
                    n_features = X.shape[1]
                
                if len(y) > 0:
                    y_stats = f"–ú–µ–¥–∏–∞–Ω–∞: {np.median(y):.1f}\n–°—Ä–µ–¥–Ω–µ–µ: {np.mean(y):.1f}\n–°—Ç–¥: {np.std(y):.1f}"
                else:
                    y_stats = "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
                
                info_text = f"""
                –ò–ù–§–û–†–ú–ê–¶–ò–Ø:
                
                –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {shape_info}
                –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {X.shape[0]:,}
                –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {n_features}
                –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ—Ç: {len(np.unique(y)) if len(y) > 0 else 0}
                
                –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ù–û–¢:
                {y_stats}
                
                –ü–†–ò–ó–ù–ê–ö–ò:
                Min: {X.min():.3f}
                Max: {X.max():.3f}
                Mean: {X.mean():.3f}
                Std: {X.std():.3f}
                """
                plt.text(0.1, 0.5, info_text, fontsize=9, 
                        verticalalignment='center', fontfamily='monospace')
                pbar.update(1)
            
            plt.suptitle('–ê–ù–ê–õ–ò–ó –ú–£–ó–´–ö–ê–õ–¨–ù–û–ì–û –î–ê–¢–ê–°–ï–¢–ê', fontsize=16, fontweight='bold')
            plt.tight_layout()
            
            if save_plots:
                plot_path = os.path.join(plot_dir, 'data_analysis.png')
                plt.savefig(plot_path, dpi=120, bbox_inches='tight')
                print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_path}")
            
            plt.show()
            pbar.update(n_plots - pbar.n)  
    
    def create_feature_importance_plot(self, X, y, model=None, save_path=None):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Args:
            X: –ø—Ä–∏–∑–Ω–∞–∫–∏
            y: —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            model: –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç RandomForest)
            save_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        if save_path:
            self.ensure_directory_exists(save_path)
        
        print("üìä –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        if model is None:
            from sklearn.ensemble import RandomForestClassifier
            
            if len(X.shape) == 3:
                X_2d = X.mean(axis=1)
            else:
                X_2d = X
            
            model = RandomForestClassifier(n_estimators=50, random_state=42)
            model.fit(X_2d, y)
        
        if hasattr(model, 'feature_importances_'):
            importances = model.feature_importances_
            feature_names = [f'–ü—Ä–∏–∑–Ω–∞–∫_{i}' for i in range(len(importances))]
            
            indices = np.argsort(importances)[::-1]
            
            plt.figure(figsize=(10, 6))
            plt.title("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", fontsize=14, fontweight='bold')
            plt.bar(range(min(20, len(indices))), importances[indices[:20]])
            plt.xticks(range(min(20, len(indices))), 
                      [feature_names[i] for i in indices[:20]], rotation=45, ha='right')
            plt.xlabel("–ü—Ä–∏–∑–Ω–∞–∫–∏")
            plt.ylabel("–í–∞–∂–Ω–æ—Å—Ç—å")
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=100, bbox_inches='tight')
                print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
            
            plt.show()
            
            return importances, indices
        else:
            print("‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç feature_importances_")
            return None, None
    
    def get_feature_summary(self, X, y):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º"""
        summary = {
            'n_samples': X.shape[0],
            'n_features': X.shape[-1] if len(X.shape) == 3 else X.shape[1],
            'feature_stats': {}
        }
        
        if len(X.shape) == 3:
            X_flat = X.reshape(-1, X.shape[-1])
        else:
            X_flat = X
        
        for i in range(min(10, X_flat.shape[1])):
            summary['feature_stats'][f'feature_{i}'] = {
                'mean': float(np.mean(X_flat[:, i])),
                'std': float(np.std(X_flat[:, i])),
                'min': float(np.min(X_flat[:, i])),
                'max': float(np.max(X_flat[:, i])),
                'median': float(np.median(X_flat[:, i]))
            }
        
        if len(y) > 0:
            summary['target_stats'] = {
                'n_classes': len(np.unique(y)),
                'class_distribution': {int(cls): int(count) 
                                      for cls, count in zip(*np.unique(y, return_counts=True))}
            }
        else:
            summary['target_stats'] = {}
        
        return summary


    def get_fitted_scaler(self):
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ scaler
        
        Returns:
            –æ–±—É—á–µ–Ω–Ω—ã–π scaler –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω
        """
        if hasattr(self.scaler, 'mean_') and hasattr(self.scaler, 'scale_'):
            return self.scaler
        else:
            print("‚ö†Ô∏è Scaler –Ω–µ –±—ã–ª –æ–±—É—á–µ–Ω!")
            return None
    